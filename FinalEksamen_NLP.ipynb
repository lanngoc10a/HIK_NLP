{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8be5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/lan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer #see below about \"lemmatization\"\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2babb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Exam_MB210_NLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9db2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>148.0</td>\n",
       "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...</td>\n",
       "      <td>Released</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>165.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>132.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  245000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  250000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  260000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                       homepage      id  \\\n",
       "0                   http://www.avatarmovie.com/   19995   \n",
       "1  http://disney.go.com/disneypictures/pirates/     285   \n",
       "2   http://www.sonypictures.com/movies/spectre/  206647   \n",
       "3            http://www.thedarkknightrises.com/   49026   \n",
       "4          http://movies.disney.com/john-carter   49529   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "2                                   Spectre   \n",
       "3                     The Dark Knight Rises   \n",
       "4                               John Carter   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "2  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "3  Following the death of District Attorney Harve...  112.312950   \n",
       "4  John Carter is a war-weary, former military ca...   43.926995   \n",
       "\n",
       "                                production_companies  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
       "2  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...   \n",
       "3  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...   \n",
       "4        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "1  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2007-05-19   961000000   \n",
       "2  [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-10-26   880674609   \n",
       "3  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-07-16  1084939099   \n",
       "4  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07   284139100   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1    169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "2    148.0  [{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"},...  Released   \n",
       "3    165.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "4    132.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "2                           A Plan No One Escapes   \n",
       "3                                 The Legend Ends   \n",
       "4            Lost in our world, found in another.   \n",
       "\n",
       "                                      title  vote_average  vote_count  \n",
       "0                                    Avatar           7.2       11800  \n",
       "1  Pirates of the Caribbean: At World's End           6.9        4500  \n",
       "2                                   Spectre           6.3        4466  \n",
       "3                     The Dark Knight Rises           7.6        9106  \n",
       "4                               John Carter           6.1        2124  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3c52e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e9c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"description\"] = df[\"tagline\"].astype(str) + \" \" + df[\"overview\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "315e5f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Enter the World of Pandora. In the 22nd centur...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcff9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus): #same as previous sessions\n",
    "    stops = stopwords.words('english') #getting the english stop words list from NLTK\n",
    "    corpusTokens = [word_tokenize(item) for item in corpus] #tokenizing with the word_tokenize method of NLTK\n",
    "    def tokenCleaner(token): \n",
    "        return lemmatizer.lemmatize(re.sub('[^A-ZÆØÅa-zæøå0-9]','',token.strip().lower()))\n",
    "    vocabulary = list() #initializing empty vocabulary as list\n",
    "    for index,item in enumerate(corpusTokens): #looping over each document (which has been tokenized)\n",
    "        documentTokens = [tokenCleaner(word) \n",
    "            for word in item if tokenCleaner(word) and word not in stops]  \n",
    "        corpusTokens[index] = documentTokens  \n",
    "        vocabulary += documentTokens  \n",
    "    corpusNonstop = [(' ').join(document) for document in corpusTokens]  \n",
    "    return corpusTokens, corpusNonstop, set(vocabulary)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "498a5ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Enter the World of Pandora. In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df['description'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTokens, corpusNonstop, vocabulary = preprocessing(df.description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd30942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['enter', 'world', 'pandora', 'in', '22nd', 'century', 'paraplegic', 'marine', 'dispatched', 'moon', 'pandora', 'unique', 'mission', 'becomes', 'torn', 'following', 'order', 'protecting', 'alien', 'civilization'] \n",
      "\n",
      " enter world pandora in 22nd century paraplegic marine dispatched moon pandora unique mission becomes torn following order protecting alien civilization \n",
      "\n",
      " ['respective', 'vigilantism', 'arkansas', 'necktie', 'calling', 'warring', 'salondeprovence', 'taliban', 'planet', 'tasker', 'produce', 'campmate', 'impersonal', 'misunderstanding', 'munday', 'psychology', 'minute', 'adoration', 'accursed', 'bolder']\n"
     ]
    }
   ],
   "source": [
    "print(corpusTokens[0],'\\n\\n',corpusNonstop[0], '\\n\\n', list(vocabulary)[:20]) #inspecting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dcfb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(word_tokenize((' ').join(corpusNonstop)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "367ad87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"corpusNonstop\"] = corpusNonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f7c4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac6a9c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent 0:00:00.754813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "word       \n",
       "s      3163\n",
       "the    1821\n",
       "a      1678\n",
       "life   1320\n",
       "one    1007"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin_time = datetime.now()\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "divide = 1 #variable to vary the fraction of the dataset that is computed, i.e. when testing code\n",
    "\n",
    "itermax = len(corpusTokens)//divide #the maximum number of iterations, function of 'divide'\n",
    "\n",
    "count_all = Counter(corpusTokens[0]) #creating a counter, counting for first document\n",
    "\n",
    "for i in range(1, itermax):\n",
    "    count_all.update(Counter(corpusTokens[i])) #updating counter object with counts from all other docs.\n",
    "    iteration+=1\n",
    "\n",
    "countAllWords = count_all #storing the total counts in a second container (counter object)\n",
    "\n",
    "\n",
    "#creating a DataFrame of the counter's top 20 words, setting column names and index\n",
    "count_all = pd.DataFrame(count_all.most_common(20)).rename(columns={0:'word',1:'count'}).set_index('word')\n",
    "\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('time spent',end_time-begin_time)\n",
    "count_all.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed04f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def get_top_n_words(n_top_words, count_vectorizer, text_data):\n",
    "    '''\n",
    "    returns a tuple of the top n words in a sample and their \n",
    "    accompanying counts, given a CountVectorizer object and text sample\n",
    "    '''\n",
    "    vectorized_headlines = count_vectorizer.fit_transform(text_data.values)\n",
    "    vectorized_total = np.sum(vectorized_headlines, axis=0)\n",
    "    word_indices = np.flip(np.argsort(vectorized_total)[0,:], 1)\n",
    "    word_values = np.flip(np.sort(vectorized_total)[0,:],1)\n",
    "    \n",
    "    word_vectors = np.zeros((n_top_words, vectorized_headlines.shape[1]))\n",
    "    for i in range(n_top_words):\n",
    "        word_vectors[i,word_indices[0,i]] = 1\n",
    "\n",
    "    words = [word[0].encode('ascii').decode('utf-8') for \n",
    "             word in count_vectorizer.inverse_transform(word_vectors)]\n",
    "\n",
    "    return (words, word_values[0,:n_top_words].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d835d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7810a5c3",
   "metadata": {},
   "source": [
    "# TF-IDF representation on description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a06227",
   "metadata": {},
   "source": [
    "TF-IDF: term frequency times inverse document frequency. \n",
    "\n",
    "•Term frequencies are the counts of each word in a document\n",
    "\n",
    "•Inverse document frequency means the inverse document frequency. The number of documents that contain that word goes up, the IDF (and hence the TF-IDF) for that word will go down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusRaw = df.description\n",
    "corpusLabels = df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countDoc(document):\n",
    "    from collections import Counter\n",
    "    counts = Counter(document)\n",
    "    return counts\n",
    "\n",
    "def createBoW_tf(document, vocabulary):\n",
    "    resultVector = []\n",
    "    for word in vocabulary:\n",
    "        if word in document:\n",
    "            resultVector.append(countDoc(document)[word] / len(document))\n",
    "        else:\n",
    "            resultVector.append(0)\n",
    "    return resultVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfMatrix = []\n",
    "for document in corpusTokens:\n",
    "    tfMatrix.append(createBoW_tf(document, vocabulary))\n",
    "#tfMatrix = np.array(tfMatrix)\n",
    "tfMatrix = csr_matrix(tfMatrix)\n",
    "print('shape',tfMatrix.shape)\n",
    "from random import random\n",
    "randomItem = int(random()*len(corpusRaw))\n",
    "print('\\nShowing vector for '+corpusLabels[randomItem]+'\\n\\n',np.round(tfMatrix[randomItem],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfce369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity between these three documents, and scaling results between 0 and 1\n",
    "pairwise_TF = tfMatrix*tfMatrix.T\n",
    "pairwise_TF = MinMaxScaler().fit_transform(pairwise_TF.toarray().reshape(-1,1)).reshape(len(corpusRaw),len(corpusRaw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pairwise_TF,columns=corpusLabels,index=corpusLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tr_tf = TfidfVectorizer(use_idf=True) #initializing the vectorizer\n",
    "tf = v_tr_tf.fit_transform(corpusNonstop).toarray() #fit, transform corpus\n",
    "vocabulary_trained = v_tr_tf.vocabulary_.keys() #get vocabulary from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "tf = csr_matrix(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a0b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise = tf*tf.T\n",
    "\n",
    "for i in range(pairwise.shape[0]):\n",
    "    pairwise[i,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb8afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 2\n",
    "numberOfMatches = 2\n",
    "\n",
    "results = np.argsort(pairwise.toarray()[source]).tolist()[-numberOfMatches:]\n",
    "results.reverse()\n",
    "\n",
    "\n",
    "print('query:')\n",
    "print(corpusRaw[source])\n",
    "print('----------')\n",
    "print()\n",
    "print('results:')\n",
    "print()\n",
    "for result in results:\n",
    "    print(corpusRaw[result])\n",
    "    print('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d6188",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((pairwise).toarray(),columns=corpusLabels,index=corpusLabels) #output pairwise similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84374285",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b60cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tr_tfidf = TfidfVectorizer(min_df=1, use_idf=True, vocabulary=vocabulary_trained) #using IDF also with Scikit-learn\n",
    "tfidf = v_tr_tfidf.fit_transform(corpusNonstop) \n",
    "pd.DataFrame((tfidf*tfidf.T).toarray(),columns=corpusLabels, index=corpusLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.title==\"Spider-Man\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57348106",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesRaw = [ \"\"\" 'With great power comes great responsibility. \"\"\"\n",
    "               \"\"\"After being bitten by a genetically altered spider, \"\"\"\n",
    "               \"\"\"nerdy high school student Peter Parker is endowed with amazing powers' \"\"\"  \n",
    "             ]\n",
    "\n",
    "queryLabels = ['Spider-Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c348089",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesNonstop = preprocessing(queriesRaw)[1] #preprocessing the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d444cbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesNonstop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "queriesNonstop = preprocessing(queriesRaw)[1] #preprocessing the queries\n",
    "\n",
    "tfidfWithQueries = v_tr_tfidf.fit_transform(corpusNonstop)\n",
    "\n",
    "Spider_Man_Similary_Df = pd.DataFrame((tfidfWithQueries*tfidfWithQueries.T).toarray(), \n",
    "             columns=corpusLabels, \n",
    "             index=corpusLabels)[queryLabels].drop(queryLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e04f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spider_Man_Similary_Df.sort_values(\"Spider-Man\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d4c547",
   "metadata": {},
   "source": [
    "# LDiA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8919e",
   "metadata": {},
   "source": [
    "•Compute the average position (centroid) of all the TF-IDF vectors \n",
    "within the class (such as spam SMS messages).\n",
    "\n",
    "•Compute the average position (centroid) of all the TF-IDF vectors \n",
    "not in the class (such as nonspam SMS messages).\n",
    "\n",
    "•Compute the vector difference between the centroids (the line \n",
    "that connects them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271f4c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sms-spam.csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a31d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "\n",
    "tfidf_model = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf_model.fit_transform(raw_documents=corpusNonstop).toarray()\n",
    "print(tfidf_docs.shape)\n",
    "print(type(tfidf_model.fit_transform(raw_documents=corpusNonstop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_model.get_feature_names()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1284e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7080811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "\n",
    "n_samples = 4837\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 5\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\"\n",
    ")\n",
    "tfidf = tfidf_vectorizer.fit_transform(df[\"corpusNonstop\"])\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf893688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f895eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another implementation with more visualization\n",
    "\n",
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_components,\n",
    "    max_iter=5,\n",
    "    learning_method=\"online\",\n",
    "    learning_offset=50.0,\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "lda.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot_top_words, see sklearn documentation: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "\n",
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    # plt.show()\n",
    "    plt.savefig('topics.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a39a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda.components_)\n",
    "%matplotlib inline\n",
    "plot_top_words(lda, tfidf_feature_names, n_top_words, \"Topics in LDA model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d105044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
